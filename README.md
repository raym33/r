# R CLI ğŸš€

**Tu AI Operating System local** - 100% privado, 100% offline, 100% tuyo.

R CLI es un agente AI en terminal potenciado por LLMs open source locales (LM Studio, Ollama). Inspirado en el CEO CLI viral de Paul Klein, pero diseÃ±ado para funcionar **completamente offline**.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•—                        â•‘
â•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—      â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘                        â•‘
â•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘                        â•‘
â•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘                        â•‘
â•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘      â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘                        â•‘
â•‘     â•šâ•â•  â•šâ•â•       â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## âœ¨ CaracterÃ­sticas

- ğŸ”’ **100% Local** - Tus datos nunca salen de tu mÃ¡quina
- ğŸš€ **Skills modulares** - PDF, SQL, cÃ³digo, resÃºmenes y mÃ¡s
- ğŸ® **UI Ã©pica** - Animaciones estilo PS2/Matrix en terminal
- ğŸ§  **RAG integrado** - Base de conocimiento persistente
- ğŸ”Œ **Extensible** - Crea tus propios skills fÃ¡cilmente
- ğŸ’° **Gratis** - Sin APIs de pago ni suscripciones

## ğŸ› ï¸ Requisitos

- Python 3.10+
- [LM Studio](https://lmstudio.ai/) o [Ollama](https://ollama.ai/)
- 16GB+ RAM (24GB VRAM recomendado para modelos grandes)

### Modelos recomendados

| Modelo | VRAM | Uso |
|--------|------|-----|
| Qwen2.5-7B | 8GB | RÃ¡pido, tareas simples |
| Qwen2.5-32B | 20GB | Equilibrado |
| Qwen2.5-72B (Q4) | 24GB | MÃ¡xima calidad |
| DeepSeek-Coder | 16GB | Especializado en cÃ³digo |

## ğŸ“¦ InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/tuusuario/r-cli.git
cd r-cli

# Instalar con pip
pip install -e .

# O con uv (mÃ¡s rÃ¡pido)
uv pip install -e .
```

## ğŸš€ Uso rÃ¡pido

### 1. Inicia tu servidor LLM

**LM Studio:**
1. Abre LM Studio
2. Carga un modelo (ej: Qwen2.5-32B-Instruct)
3. Inicia el servidor local (puerto 1234)

**Ollama:**
```bash
ollama run qwen2.5:32b
```

### 2. Lanza R CLI

```bash
# Modo interactivo
r

# Chat directo
r chat "Explica quÃ© es machine learning"

# Skills directos
r pdf "Mi informe sobre IA" --title "Informe Q4"
r sql ventas.csv "SELECT * FROM data WHERE aÃ±o = 2024"
r resume documento.pdf --style detailed
r code "funciÃ³n para ordenar lista" --run
```

## ğŸ“š Skills disponibles

| Skill | DescripciÃ³n | Ejemplo |
|-------|-------------|---------|
| `pdf` | Genera documentos PDF | `r pdf "contenido" --template business` |
| `resume` | Resume documentos largos | `r resume archivo.pdf` |
| `sql` | Consultas SQL sobre CSVs/DBs | `r sql data.csv "SELECT *"` |
| `code` | Genera y ejecuta cÃ³digo | `r code "hola mundo" --run` |
| `fs` | Operaciones de archivos | `r ls --pattern "*.py"` |

## âš™ï¸ ConfiguraciÃ³n

Crea `~/.r-cli/config.yaml`:

```yaml
llm:
  provider: lm-studio  # o 'ollama'
  base_url: http://localhost:1234/v1
  model: local-model
  temperature: 0.7

ui:
  theme: ps2  # ps2, matrix, minimal, retro, cyberpunk

rag:
  enabled: true
  persist_directory: ~/.r-cli/vectordb
```

## ğŸ¨ Temas

```bash
r --theme matrix   # Verde estilo Matrix
r --theme ps2      # Azul PlayStation 2
r --theme minimal  # Limpio y simple
r --theme retro    # CRT vintage
```

## ğŸ”§ Crear tu propio Skill

```python
# ~/.r-cli/skills/mi_skill.py

from r_cli.core.agent import Skill
from r_cli.core.llm import Tool

class MiSkill(Skill):
    name = "mi_skill"
    description = "Mi skill personalizado"

    def get_tools(self) -> list[Tool]:
        return [
            Tool(
                name="mi_funcion",
                description="Hace algo Ãºtil",
                parameters={...},
                handler=self.mi_funcion,
            )
        ]

    def mi_funcion(self, arg1: str) -> str:
        return f"Resultado: {arg1}"
```

## ğŸ—ºï¸ Roadmap

- [x] Core agentic con LM Studio/Ollama
- [x] Skills: PDF, SQL, Code, Resume, Filesystem
- [x] UI con animaciones PS2/Matrix
- [x] RAG persistente
- [ ] Voice mode (Whisper + Piper TTS)
- [ ] IntegraciÃ³n Stable Diffusion para diseÃ±o
- [ ] Multi-agent orchestration
- [ ] Plugin marketplace

## ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas!

1. Fork el repositorio
2. Crea una rama (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agrega nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“„ Licencia

MIT License - Usa R CLI como quieras.

---

**R CLI** - Porque tu IA deberÃ­a ser tuya. ğŸ”’
